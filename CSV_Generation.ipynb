{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "#! python -m pip install -U pycld2\n",
    "import pycld2 as cld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "determines if sentence language is english\n",
    "\"\"\"\n",
    "def is_english(sentence):\n",
    "    if (len(sentence) < 3):\n",
    "        return False\n",
    "    _, _, details = cld2.detect(sentence)\n",
    "    if (details[0][0] != \"ENGLISH\"):\n",
    "        #print(sentence)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: \n",
    "    Text file containing all the generated fake reviews from GPT2 fine tuned model\n",
    "Output:\n",
    "    Saves a 'fake_reviews.csv' in the current directory that labels every review as fake\n",
    "    \n",
    "Fake reviews are filtered to remove \\n symbol and the GTP2 model \n",
    "included some lines containing only equal signs which are also removed.\n",
    "\"\"\"\n",
    "def create_df_from_txt(path):\n",
    "    \n",
    "    review_list = []\n",
    "    substr = \"======\"\n",
    "    with open(path, 'r') as generated_reviews:\n",
    "        for line in generated_reviews:\n",
    "            #append all lines that are not equal signs\n",
    "            if substr not in line:\n",
    "                #remove newline token with [:-1]\n",
    "                review_list.append(line[:-1])\n",
    "                \n",
    "    df = pd.DataFrame(review_list, columns=['Review'])\n",
    "    df['Real'] = 0\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df.to_csv(\"fake_reviews.csv\", index=False)\n",
    "    print(\"Saved fake_reviews.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fake_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "generate_reviews_path = \"Data/gpt_2_gen_texts.txt\"\n",
    "d = create_df_from_txt(generate_reviews_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_reviews = pd.read_csv(\"Data/real_reviews.csv\")\n",
    "fake_reviews = pd.read_csv(\"Data/fake_reviews.csv\")\n",
    "fake_reviews.dropna(inplace=True)\n",
    "real_reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An appetizer, 2 HUGE dinners, and beer for 35 bucks.  Yes.  Lots to choose from on the menu.  Good service.  We will be back.'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_reviews.Review.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\",disable=[\"tagger\", \"parser\"])\n",
    "\"\"\"\n",
    "Returns the lemma form of all words in the given sentence, also removes any non alphabetic words, ie punctuation\n",
    "\"\"\"\n",
    "def get_lemmatized_words(text):\n",
    "    doc = nlp(text)\n",
    "    sentence = []\n",
    "    for token in doc:\n",
    "        if (token.lemma_.isalpha()):\n",
    "            sentence.append(token.lemma_)\n",
    "    return sentence\n",
    "\n",
    "def preprocess(data):\n",
    "    res = []\n",
    "    for rev in data.Review.values:\n",
    "        tmp = \" \".join(get_lemmatized_words(rev))\n",
    "        #if its a longer sentence check the language\n",
    "        if (len(tmp) > 40):\n",
    "            if (is_english(tmp) == True):\n",
    "                res.append(tmp)\n",
    "        else:\n",
    "            res.append(tmp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = preprocess(fake_reviews)\n",
    "r = preprocess(real_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.DataFrame(r, columns=['Review'])\n",
    "real['Real'] = 1\n",
    "fake = pd.DataFrame(f, columns=['Review'])\n",
    "fake['Real'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50% real 50% fake in order to avoid biased data\n",
    "real = real.iloc[0:fake.shape[0]]\n",
    "assert(real.shape == fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([fake, real], ignore_index=True)\n",
    "merged_df.to_csv(\"classifier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
